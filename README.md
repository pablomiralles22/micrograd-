# micrograd++

This is a personal project for learning purposes. I am building an engine that creates operation trees and implements backpropagation. The goal is to build a neural network library on top of it.

## Roadmap

- [X] Implement very basic operations for dimensions one and two.
- [ ] Implement tensor operations.
- [ ] Implement MLP.
- [ ] Implement gradient descent.
- [ ] Implement SGD.
- [ ] Implement ADAM optimizer.
